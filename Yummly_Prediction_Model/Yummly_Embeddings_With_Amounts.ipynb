{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_dim=100\n",
    "G=4\n",
    "#batch_size=80\n",
    "number_of_negative_tokens = 5\n",
    "n_epochs = 30\n",
    "n_workers=64\n",
    "queue_size = 64\n",
    "padding_length=3\n",
    "title_length_percentile=95\n",
    "desc_length_percentile=90\n",
    "\n",
    "import os, time, json,pandas as pd, numpy as np, re, string, random,sys\n",
    "from collections import Counter,defaultdict\n",
    "import Levenshtein\n",
    "\n",
    "\n",
    "from keras.layers import Input,Lambda,Conv1D,GlobalMaxPool1D,concatenate,Dense,Dropout,PReLU,TimeDistributed,Embedding,Activation\n",
    "from keras import Model\n",
    "import keras.backend as K\n",
    "import keras\n",
    "from keras.utils import Sequence\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "\n",
    "df= pd.read_csv('yummly.csv')\n",
    "\n",
    "\n",
    "# In[7]:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    30405\n",
       "2    26269\n",
       "3    15468\n",
       "4     8259\n",
       "5     4050\n",
       "0     3357\n",
       "6     1413\n",
       "7      192\n",
       "Name: WHO, dtype: int64"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.WHO.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RECIPE</th>\n",
       "      <th>WHO</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>toasted sesame oil#4.533333333333333,olive oil#53.099999999999994,nut butter#129.0,cider vinegar#58.60666666666667,honey#61.019999999999996,ground cayenne pepper#0.22499999999999998,lime wedges#33.5,fresh spinach#142.0,spearmint#13.0,spring onions#75.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                         RECIPE  \\\n",
       "0  toasted sesame oil#4.533333333333333,olive oil#53.099999999999994,nut butter#129.0,cider vinegar#58.60666666666667,honey#61.019999999999996,ground cayenne pepper#0.22499999999999998,lime wedges#33.5,fresh spinach#142.0,spearmint#13.0,spring onions#75.0   \n",
       "\n",
       "   WHO  \n",
       "0    2  "
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.options.display.max_colwidth= 500\n",
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip3 install python-levenshtein\n",
    "#!pip3 install setuptools\n",
    "\n",
    "# strip punctuation and combine ingredients into one word separated by a spae\n",
    "\n",
    "df['RECIPE'] = df['RECIPE'].str.replace('\\d+', '') #strip all digits\n",
    "df['RECIPE'] = df['RECIPE'].str.replace(' ', '')\n",
    "df['RECIPE'] = df['RECIPE'].str.replace('#.,', ' ')\n",
    "df['RECIPE'] = df['RECIPE'].str.replace('#.', '')\n",
    "\n",
    "#df['RECIPE'] = df['RECIPE'].str.replace(' ', '')\n",
    "#df['RECIPE'] = df['RECIPE'].str.replace(' ', '')\n",
    "#df['RECIPE'] = df['RECIPE'].str.replace('#', ' ')\n",
    "#df['RECIPE'] = df['RECIPE'].str.replace(r'[\\s^\\w]', '')\n",
    "#df['RECIPE'] = df['RECIPE'].str.replace(' ', '')\n",
    "#df['RECIPE'] = df['RECIPE'].str.replace(',', ' ')\n",
    "#df['RECIPE'] = df['RECIPE'].str.replace('\\d', ' ')\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RECIPE</th>\n",
       "      <th>WHO</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>toastedsesameoil oliveoil nutbutter cidervinegar honey groundcayennepepper limewedges freshspinach spearmint springonions</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>oliveoil cakeflour whiteonion choppedgarlic whitewine grapetomatoes chickenbouillon tomatopaste darkbrownsugar parsley</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fineseasalt crackedblackpepper choppedgarlic whiteonion ice freshbasil freshoregano freshthymeleaves saltedbutter shreddedparmesancheese</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>unsaltedbutter shortening darkbrownsugar whitesugar hardboiledeggs extract cakeflour bakingsoda cinnamonsticks fineseasalt rolledoats goldenraisins</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ice fineseasalt saltedbutter cakeflour crackedblackpepper sourcream</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>saltedbutter sweetpotatoes pineapple puremaplesyrup cinnamonsticks fineseasalt choppedwalnuts</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>hamburgerbuns pastasauce</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>coldmilk cakeflour oliveoil whitesugar fineseasalt meltedbutter</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>canolaoil whiteonion tofu garlicpowder cumin fineseasalt groundturmeric crackedblackpepper</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>whiteonion fineseasalt crackedblackpepper cakeflour saltedbutter coldmilk whitesugar eggyolks</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>oliveoil whiteonion whippedcream cookedchicken fineseasalt crackedblackpepper</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>celeryribs springonions shreddedsharpcheddarcheese</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                 RECIPE  \\\n",
       "0                             toastedsesameoil oliveoil nutbutter cidervinegar honey groundcayennepepper limewedges freshspinach spearmint springonions   \n",
       "1                                oliveoil cakeflour whiteonion choppedgarlic whitewine grapetomatoes chickenbouillon tomatopaste darkbrownsugar parsley   \n",
       "2              fineseasalt crackedblackpepper choppedgarlic whiteonion ice freshbasil freshoregano freshthymeleaves saltedbutter shreddedparmesancheese   \n",
       "3   unsaltedbutter shortening darkbrownsugar whitesugar hardboiledeggs extract cakeflour bakingsoda cinnamonsticks fineseasalt rolledoats goldenraisins   \n",
       "4                                                                                   ice fineseasalt saltedbutter cakeflour crackedblackpepper sourcream   \n",
       "5                                                         saltedbutter sweetpotatoes pineapple puremaplesyrup cinnamonsticks fineseasalt choppedwalnuts   \n",
       "6                                                                                                                              hamburgerbuns pastasauce   \n",
       "7                                                                                       coldmilk cakeflour oliveoil whitesugar fineseasalt meltedbutter   \n",
       "8                                                            canolaoil whiteonion tofu garlicpowder cumin fineseasalt groundturmeric crackedblackpepper   \n",
       "9                                                         whiteonion fineseasalt crackedblackpepper cakeflour saltedbutter coldmilk whitesugar eggyolks   \n",
       "10                                                                        oliveoil whiteonion whippedcream cookedchicken fineseasalt crackedblackpepper   \n",
       "11                                                                                                   celeryribs springonions shreddedsharpcheddarcheese   \n",
       "\n",
       "    WHO  \n",
       "0     2  \n",
       "1     2  \n",
       "2     1  \n",
       "3     2  \n",
       "4     2  \n",
       "5     3  \n",
       "6     2  \n",
       "7     5  \n",
       "8     3  \n",
       "9     5  \n",
       "10    1  \n",
       "11    1  "
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['WHO'] = df['WHO'].replace({0:'zero', 1: 'one', 2: 'two', 3: 'three', 4: 'four', 5: 'five', 6: 'six', 7: 'seven'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RECIPE</th>\n",
       "      <th>WHO</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>toastedsesameoil oliveoil nutbutter cidervinegar honey groundcayennepepper limewedges freshspinach spearmint springonions</td>\n",
       "      <td>two</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>oliveoil cakeflour whiteonion choppedgarlic whitewine grapetomatoes chickenbouillon tomatopaste darkbrownsugar parsley</td>\n",
       "      <td>two</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fineseasalt crackedblackpepper choppedgarlic whiteonion ice freshbasil freshoregano freshthymeleaves saltedbutter shreddedparmesancheese</td>\n",
       "      <td>one</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>unsaltedbutter shortening darkbrownsugar whitesugar hardboiledeggs extract cakeflour bakingsoda cinnamonsticks fineseasalt rolledoats goldenraisins</td>\n",
       "      <td>two</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                RECIPE  \\\n",
       "0                            toastedsesameoil oliveoil nutbutter cidervinegar honey groundcayennepepper limewedges freshspinach spearmint springonions   \n",
       "1                               oliveoil cakeflour whiteonion choppedgarlic whitewine grapetomatoes chickenbouillon tomatopaste darkbrownsugar parsley   \n",
       "2             fineseasalt crackedblackpepper choppedgarlic whiteonion ice freshbasil freshoregano freshthymeleaves saltedbutter shreddedparmesancheese   \n",
       "3  unsaltedbutter shortening darkbrownsugar whitesugar hardboiledeggs extract cakeflour bakingsoda cinnamonsticks fineseasalt rolledoats goldenraisins   \n",
       "\n",
       "   WHO  \n",
       "0  two  \n",
       "1  two  \n",
       "2  one  \n",
       "3  two  "
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.options.display.max_colwidth= 500\n",
    "df.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "#(X_train, X_test) = train_test_split(df2,test_size=0.20)\n",
    "\n",
    "\n",
    "#with tf.device('/gpu:0'):\n",
    "X_train, X_validation, X_test = np.split(df.sample(frac=1), [int(.6*len(df)), int(.8*len(df))])\n",
    "\n",
    "descTokenCounts = pd.Series(' '.join(df['RECIPE']).split())\n",
    "\n",
    "descTokenCounts= descTokenCounts.value_counts().to_dict()\n",
    "\n",
    "df= df.drop_duplicates()\n",
    "\n",
    "\n",
    "df= df.dropna()\n",
    "\n",
    "\n",
    "def remove_non_ascii_1(text):\n",
    "\n",
    "    return ''.join([i if ord(i) < 128 else ' ' for i in text])\n",
    "\n",
    "def remove_non_ascii_2(text):\n",
    "\n",
    "    return re.sub(r'[^\\x20-\\x7E]+',' ', text)\n",
    "\n",
    "vocabSize=100000\n",
    "tokens = sorted(descTokenCounts.items(),key=lambda x:x[1],reverse=True)[:vocabSize]\n",
    "\n",
    "tokens = [i[0] for i in tokens]\n",
    "tokens.append('token_unknown')\n",
    "token_to_index = {}\n",
    "index_to_token = {}\n",
    "\n",
    "\n",
    "df['WHO'] = ([remove_non_ascii_1(sentence) for sentence in df['WHO']])\n",
    "df['WHO'] = ([remove_non_ascii_2(sentence) for sentence in df['WHO']])\n",
    "\n",
    "\n",
    "df['RECIPE']= ([remove_non_ascii_1(sentence) for sentence in df['RECIPE']])\n",
    "\n",
    "\n",
    "# In[13]:\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "df['RECIPE']= ([remove_non_ascii_2(sentence) for sentence in df['RECIPE']])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'allmy_jermaine_model1_jerm'\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "#(X_train, X_test) = train_test_split(df2,test_size=0.20)\n",
    "\n",
    "\n",
    "#with tf.device('/gpu:0'):\n",
    "X_train, X_validation, X_test = np.split(df.sample(frac=1), [int(.6*len(df)), int(.8*len(df))])\n",
    "\n",
    "\n",
    "\n",
    "with open('alltrain_data.json', 'wb') as f:\n",
    "    f.write(X_train.to_json(orient='records', lines=True).encode('ascii', 'ignore'))\n",
    "\n",
    "    \n",
    "with open('alltest_data.json', 'wb') as g:\n",
    "    g.write(X_test.to_json(orient='records', lines=True).encode('ascii', 'ignore'))\n",
    "\n",
    "\n",
    "    \n",
    "with open('allvalidation_data.json', 'wb') as t:\n",
    "    t.write(X_validation.to_json(orient='records', lines=True).encode('ascii', 'ignore'))\n",
    "\n",
    "def loadData(dataPath):\n",
    "    data=[]\n",
    "    start_time = time.time()\n",
    "    with open(dataPath) as f:\n",
    "        for line in f:\n",
    "            data.append(line)\n",
    "    loadTime = time.time() - start_time\n",
    "\n",
    "    #print loadTime\n",
    "    return data\n",
    "\n",
    "training_data = loadData('alltrain_data.json')\n",
    "validation_data = loadData('allvalidation_data.json') \n",
    "test_data = loadData('alltest_data.json') \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_length= df['WHO'].map(len)\n",
    "desc_length= df['RECIPE'].map(len)\n",
    "titleCounts = df['WHO'].value_counts().to_dict()\n",
    "\n",
    "charset=set(list(string.ascii_lowercase)+list(map(str,range(10)))+list(\"?$*!: @ ^ %- / <> ~ ` \\\\ [] {} \\n = | \\\" _+#&-/\\n %() ' '.;,\"))\n",
    "title_char_to_index_dict={c:i for i,c in enumerate(charset)}\n",
    "title_index_to_char_dict={i:c for c,i in title_char_to_index_dict.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'?': 0, '9': 1, 'c': 2, 'h': 3, '3': 4, ')': 5, 'b': 6, 'd': 7, 'g': 8, '@': 9, '`': 10, '=': 11, '#': 12, '|': 13, '7': 14, ';': 15, 'n': 16, '*': 17, 'z': 18, '[': 19, 'l': 20, '4': 21, '}': 22, 'f': 23, 'v': 24, '6': 25, 'r': 26, '2': 27, ',': 28, '{': 29, '1': 30, 'm': 31, 'i': 32, 'k': 33, '<': 34, '/': 35, '~': 36, '$': 37, '^': 38, '_': 39, ':': 40, 'e': 41, '%': 42, ']': 43, 'y': 44, 'j': 45, 'u': 46, '8': 47, '.': 48, 'a': 49, ' ': 50, '!': 51, 'w': 52, 'x': 53, '>': 54, 'o': 55, 'p': 56, 't': 57, '+': 58, '&': 59, '\\\\': 60, '-': 61, '5': 62, 's': 63, '0': 64, '(': 65, \"'\": 66, 'q': 67, '\"': 68, '\\n': 69}\n"
     ]
    }
   ],
   "source": [
    "print(title_char_to_index_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "for i in range(len(tokens)):\n",
    "    token_to_index[tokens[i]] = i+1\n",
    "    index_to_token[i+1] = tokens[i] \n",
    "\n",
    "\n",
    "with open('allmodels_indices.json'.format(model_name),'w') as f:\n",
    "    json.dump({'title_char_to_index_dict':title_char_to_index_dict,'title_index_to_char_dict':title_index_to_char_dict,              'token_to_index':token_to_index,'index_to_token':index_to_token},f)\n",
    "\n",
    "\n",
    "    \n",
    "title_max_len = np.ceil(np.percentile(title_length, title_length_percentile)).astype(int)\n",
    "\n",
    "def title_char_tokenizer(entity,entity_max_len):\n",
    "    preproced_entity=(\" \"*padding_length+entity)[:entity_max_len]\n",
    "    padded_entity=preproced_entity+\"\".join([\" \"]*(entity_max_len-len(preproced_entity)))\n",
    "    return [title_char_to_index_dict[i] for i in padded_entity]\n",
    "\n",
    "\n",
    "## RECIPE tokenizer\n",
    "## 0 padded in the end\n",
    "desc_max_length = np.ceil(np.percentile(desc_length, desc_length_percentile)).astype(int)\n",
    "def job_description_tokenizer(desc,entity_max_len):\n",
    "    desc = re.sub(\"[,\\/]\",' ',desc).split()\n",
    "    desc = [token_to_index[i] if i in token_to_index else token_to_index['token_unknown'] for i in desc]\n",
    "    desc=(desc+[0]*entity_max_len)[:entity_max_len]\n",
    "    return desc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open ('allallmodels_model_params.json'.format(model_name),'w') as f:\n",
    "    json.dump({'title_max_len':int(title_max_len),'desc_max_length':int(desc_max_length)},f)\n",
    "    \n",
    "## character embedding model for a list of titles\n",
    "def char_embed_model_seq(input_layer,char_length,char_index_dict,entity_name,n_filters=512,embed_dim=embed_dim):\n",
    "    '''\n",
    "    Same as char_embed_model, but produces embeddings for a sequence of say, titles.\n",
    "    Applies the same layers (as char_embed_model) to each member of the sequence\n",
    "    '''    \n",
    "    entity_onehot_layer=TimeDistributed(Lambda(lambda x: K.one_hot(x,len(char_index_dict)),output_shape=(char_length,len(char_index_dict))),name=entity_name+'_onehot_seq')(input_layer)\n",
    "        \n",
    "    conv7_layer=TimeDistributed(Conv1D(filters=n_filters,kernel_size=4,activation='relu'),name=entity_name+'_conv_7seq')(entity_onehot_layer)\n",
    "    maxpool7_layer=TimeDistributed(GlobalMaxPool1D(),name=entity_name+'maxpool1seq')(conv7_layer)\n",
    "\n",
    "    conv3_layer=TimeDistributed(Conv1D(filters=n_filters,kernel_size=2,activation='relu'),name=entity_name+'_conv_3seq')(entity_onehot_layer)\n",
    "    maxpool3_layer=TimeDistributed(GlobalMaxPool1D(),name=entity_name+'maxpool2seq')(conv3_layer)\n",
    "\n",
    "    pools_concat=keras.layers.concatenate([maxpool7_layer,maxpool3_layer],name=entity_name+'_maxpools_concatseq')\n",
    "    #pools_dropped=(pools_concat)\n",
    "\n",
    "    entity_dense_layer=TimeDistributed(Dense(n_filters*2,activation='relu'),name=entity_name+'_intermediate_denseseq')(pools_concat)\n",
    "    \n",
    "    dropout_layer=TimeDistributed(Dropout(0.4),name=entity_name+\"_droppedseq\")(entity_dense_layer)\n",
    "    \n",
    "    entity_final_dense=TimeDistributed(Dense(embed_dim),name=entity_name+'_last_denseseq')(dropout_layer)\n",
    "    entity_prelu_layer=TimeDistributed(PReLU(),name=entity_name+'_preluseq')(entity_final_dense)\n",
    "    embed_norm_layer=TimeDistributed(Lambda(lambda x: x/(K.epsilon()+K.sqrt(K.batch_dot(x,x,axes=-1)))),name=entity_name+'_unit_norm_embedseq')(entity_prelu_layer)\n",
    "\n",
    "    entity_embed_model=keras.models.Model(input_layer,embed_norm_layer,name=entity_name+\"_embedding_model\")\n",
    "    return entity_embed_model\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# In[25]:\n",
    "\n",
    "\n",
    "## job describtion embedding - average word embedding (remove 0 padding)\n",
    "def desc_embed_model(input_layer,vocab_size,entity_name,embed_dim=embed_dim):\n",
    "    wordEmbed = Embedding(input_dim = vocab_size,output_dim = embed_dim, name='word_embedding')(input_layer) \n",
    "    \n",
    "    ## get average embedding for desc (remove 0 padding)\n",
    "    mask=Lambda(lambda x: K.cast(K.minimum(1,K.cast(x,'int32')),'float32'),name='mask')(input_layer)\n",
    "    mask_summed=Lambda(lambda x: 1/(K.epsilon()+K.sum(x,axis=-1)),name='mask_summed')(mask)\n",
    "    mask_normed=keras.layers.multiply([mask,mask_summed],name='mask_normed')\n",
    "    desc_embedding_averaged=keras.layers.dot([wordEmbed,mask_normed],axes=1,name='desc_embedding_averaged')\n",
    "    \n",
    "    desc_embed_model=Model(input_layer,desc_embedding_averaged,name=entity_name+\"_embedding_model\")\n",
    "    return desc_embed_model\n",
    "# In[26]:\n",
    "\n",
    "\n",
    "alpha=0.5\n",
    "sampling_titles = titleCounts.keys()\n",
    "\n",
    "sampling_titles= [k for k in titleCounts.keys()]\n",
    "\n",
    "\n",
    "# In[27]:\n",
    "\n",
    "\n",
    "sampling_titles_array = np.array(sampling_titles)\n",
    "\n",
    "\n",
    "# In[28]:\n",
    "\n",
    "\n",
    "sampling_prob_array = np.array(list(titleCounts.values()))\n",
    "sampling_prob_array = np.power(sampling_prob_array,alpha)\n",
    "sampling_prob_array = sampling_prob_array/sum(sampling_prob_array)\n",
    "\n",
    "\n",
    "# In[29]:\n",
    "\n",
    "\n",
    "def sampling_based_on_similarity(title,sub_sampling_titles,number_of_negative_tokens=5):\n",
    "## Randomly sample sub_sampling_titles based on emperical distribution\n",
    "## Randomly sample titles from the selected sub-titles based on Levenshtein similarity\n",
    "    st = time.time()\n",
    "    sampling_titles = np.array(sub_sampling_titles)\n",
    "\n",
    "    sampling_prob = np.array([Levenshtein.ratio(title,i) for i in sub_sampling_titles])#Levenshtein.ratio(title,i) for i in sub_sampling_titles])\n",
    "    sampling_prob = sampling_prob/sum(sampling_prob)\n",
    "    \n",
    "    samples=np.random.choice(sampling_titles,size=number_of_negative_tokens,p=sampling_prob)\n",
    "  \n",
    "    return samples.tolist()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "class empirical_sampling_gen(Sequence):\n",
    "\n",
    "    def __init__(self, data, batch_size,number_of_negative_tokens,sampling_titles,sampling_prob,sub_sampling_size):\n",
    "        '''        \n",
    "        batch_size: number of resumes to process per batch        \n",
    "        The actual number of training samples varies as each resume is splitted into sub-sequences\n",
    "        '''\n",
    "        self.batch_size = batch_size\n",
    "        self.input_data = data\n",
    "        self.data_length = len(data)\n",
    "        self.number_negative_tokens = number_of_negative_tokens\n",
    "        self.sampling_titles = sampling_titles\n",
    "        self.sampling_prob = sampling_prob\n",
    "        self.sub_sampling_size = sub_sampling_size\n",
    "    def __len__(self):\n",
    "        return int(np.ceil(self.data_length / float(self.batch_size)))\n",
    "    \n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        i = idx\n",
    "        batch_size = self.batch_size \n",
    "        desc_input_batch=[]\n",
    "        title_input_batch=[]\n",
    "        y_pos_batch=[]\n",
    "        y_neg_batch=[] \n",
    "        titles = []\n",
    "        for k in range(i * batch_size, min((i + 1) * batch_size, self.data_length)):\n",
    "            line = json.loads(self.input_data[k])\n",
    "            desc = job_description_tokenizer(line['RECIPE'],desc_max_length)\n",
    "            #desc = str(desc)\n",
    "            titles.append(line['WHO'])\n",
    "            title = title_char_tokenizer(line['WHO'],title_max_len)\n",
    "            #title= str(title)\n",
    "            desc_input_batch.append(desc)\n",
    "            title_input_batch.append([title]*self.number_negative_tokens)\n",
    "            y_pos_batch.append(1)\n",
    "            y_neg_batch.append([0]*self.number_negative_tokens)  \n",
    "            \n",
    "        ## Sample negative titles for each batch all together              \n",
    "        neg_titles = np.random.choice(self.sampling_titles,                                                 size=len(titles)*self.number_negative_tokens,                                                 p=self.sampling_prob)\n",
    "        \n",
    "        ## Resample for titles with length below median title length based on Levenshtein similarity\n",
    "        sub_sampling_titles = np.random.choice(self.sampling_titles,p=self.sampling_prob,                                               size=self.sub_sampling_size*len(titles),replace=True)\n",
    "        for i,t in enumerate(titles):\n",
    "            if np.random.random()>0.5:\n",
    "                sub_titles = sub_sampling_titles[i*self.sub_sampling_size:(i+1)*self.sub_sampling_size]\n",
    "                samples = sampling_based_on_similarity(t,sub_titles)\n",
    "                neg_titles[i*self.number_negative_tokens:(i+1)*self.number_negative_tokens]=samples\n",
    "        \n",
    "        neg_title_input_batch = [title_char_tokenizer(t,title_max_len) for t in neg_titles]\n",
    "        neg_title_input_batch = [neg_title_input_batch[x:x+self.number_negative_tokens]                                  for x in range(0, len(neg_title_input_batch), self.number_negative_tokens)]\n",
    "        \n",
    "        \n",
    "             \n",
    "        ## Convert inputs and output to numpy arrays\n",
    "        inputs = list(map(np.array,[desc_input_batch,title_input_batch,neg_title_input_batch]))\n",
    "        outputs = list(map(np.array,[y_pos_batch,y_neg_batch]))     \n",
    "        #return (inputs, outputs,titles,neg_titles) \n",
    "        #print(inputs)\n",
    "        return (inputs, outputs) \n",
    "    \n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        #'Shuffle data after each epoch'\n",
    "        np.random.shuffle(self.input_data)\n",
    "\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "# In[31]:\n",
    "\n",
    "\n",
    "batch_size=80\n",
    "\n",
    "\n",
    "# In[32]:\n",
    "\n",
    "\n",
    "trainGen = empirical_sampling_gen(training_data,batch_size,number_of_negative_tokens,                                  sampling_titles_array,sampling_prob_array,sub_sampling_size=2200)                                 \n",
    "\n",
    "\n",
    "\n",
    "#len(title_char_to_index_dict)\n",
    "\n",
    "\n",
    "# In[33]:\n",
    "\n",
    "\n",
    "\n",
    "testGen = empirical_sampling_gen(test_data,batch_size,number_of_negative_tokens,                                    sampling_titles_array,sampling_prob_array,sub_sampling_size=1500)\n",
    "\n",
    "\n",
    "# In[34]:\n",
    "\n",
    "\n",
    "validateGen = empirical_sampling_gen(validation_data,batch_size,number_of_negative_tokens,                                    sampling_titles_array,sampling_prob_array,sub_sampling_size=2200)                                 \n",
    "\n",
    "\n",
    "# In[35]:\n",
    "\n",
    "\n",
    "target_title_input=Input(shape=(number_of_negative_tokens,title_max_len), dtype='int32', name='targe_title_input')\n",
    "neg_title_input = Input(shape=(number_of_negative_tokens,title_max_len), dtype='int32', name='ne_title_input')\n",
    "title_embedding_model = char_embed_model_seq(target_title_input,title_max_len,title_char_to_index_dict,\"titlee\")\n",
    "target_title_embed = title_embedding_model(target_title_input)\n",
    "target_title_embed = Lambda(lambda x:x[:,0,:],name='title_embedding_take_first_elemente')(target_title_embed)\n",
    "neg_title_embed = title_embedding_model(neg_title_input)\n",
    "\n",
    "\n",
    "\n",
    "# In[36]:\n",
    "\n",
    "\n",
    "## Get resume job description embedding\n",
    "desc_input = Input(shape=(desc_max_length,),name='des_input')\n",
    "desc_embedding_model = desc_embed_model(desc_input,vocabSize+2,'des')\n",
    "desc_embed = desc_embedding_model(desc_input)\n",
    "\n",
    "## Calcuate dot product and loss\n",
    "desc_target_title_dot = keras.layers.dot([target_title_embed,desc_embed],axes=-1,name='des_target_dot')\n",
    "pos_title_logit = Activation('sigmoid',name='po_title_logit')(desc_target_title_dot)\n",
    "\n",
    "desc_neg_title_dot = keras.layers.dot([neg_title_embed,desc_embed],axes=-1,name='des_neg_dot')\n",
    "neg_title_logit = Activation('sigmoid',name='ne_title_logit')(desc_neg_title_dot)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = desc_embedding_model.get_weights()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(suppress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_embeddings = {w:embeddings[idx].flatten() for w, idx in descTokenCounts.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "   #count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recipe_emb(temp, words_embeddings):\n",
    "    np.set_printoptions(suppress=True,\n",
    "    formatter={'float_kind':'{:0.46f}'.format})\n",
    "    count = 0\n",
    "    v=1\n",
    "    for w in temp.split():\n",
    "    \n",
    "        if w in words_embeddings:\n",
    "            count +=1\n",
    "            v-= ((words_embeddings[w]))\n",
    "        #v= np.array(v)\n",
    "    return (v)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.set_option('display.float_format', lambda x: '%.3f' % x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3= df[0:90000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jermainemarshall/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "df3['embed_summed']=df3['RECIPE'].apply(lambda x: recipe_emb(x,words_embeddings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RECIPE</th>\n",
       "      <th>WHO</th>\n",
       "      <th>embed_summed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>toastedsesameoil oliveoil nutbutter cidervinegar honey groundcayennepepper limewedges freshspinach spearmint springonions</td>\n",
       "      <td>two</td>\n",
       "      <td>[1.1235876, 1.1093943, 1.0867372, 0.85236037, 0.89380324, 0.8650725, 0.98391545, 0.9461132, 0.9469015, 1.0970093, 0.8552572, 1.0715595, 0.9841607, 1.013585, 0.97388107, 0.9736649, 1.0155487, 0.99108434, 0.9708908, 0.97684455, 1.1266869, 1.1471821, 0.95085275, 0.87351066, 1.1188335, 1.1121885, 1.1366059, 0.9685107, 1.029752, 0.9673499, 0.85247856, 1.1385634, 0.9708395, 1.1972069, 0.83814836, 1.0772746, 0.9607101, 1.0581956, 0.96407497, 1.0055512, 0.92251134, 0.89204025, 0.9902143, 1.0689365, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>oliveoil cakeflour whiteonion choppedgarlic whitewine grapetomatoes chickenbouillon tomatopaste darkbrownsugar parsley</td>\n",
       "      <td>two</td>\n",
       "      <td>[1.1576535, 1.0060086, 1.001102, 1.0257555, 0.965866, 1.0820988, 1.2114697, 1.0102463, 1.1409972, 0.9423051, 0.9791293, 1.1181381, 0.95848656, 0.8784251, 1.0353574, 0.9220266, 1.115515, 1.0678421, 1.2171474, 0.95343775, 1.0700219, 0.96431077, 0.96083665, 1.0005562, 1.1521571, 0.927994, 1.1126252, 0.93517196, 1.0194654, 0.9289029, 0.864626, 0.94313383, 0.9287649, 1.0493382, 0.7741933, 0.85782766, 0.89068496, 1.061048, 0.9233977, 0.98739916, 0.89586186, 0.9407691, 0.9297667, 1.0341085, 0.97049...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fineseasalt crackedblackpepper choppedgarlic whiteonion ice freshbasil freshoregano freshthymeleaves saltedbutter shreddedparmesancheese</td>\n",
       "      <td>one</td>\n",
       "      <td>[0.80973685, 0.86391956, 1.0316488, 1.0032533, 0.95308906, 0.93657243, 1.040899, 0.9817769, 1.0761225, 1.0651423, 1.0227959, 1.0026183, 1.1349108, 0.97062963, 1.2304887, 0.8398581, 1.022866, 1.0837965, 1.090834, 1.161133, 0.9819236, 1.0737371, 1.0018833, 0.95574737, 0.98670936, 0.82360303, 0.9653919, 0.8880768, 0.95349425, 1.0639567, 0.9214981, 1.0225074, 1.2548019, 1.1158266, 0.93849015, 0.896206, 0.9210321, 1.1299094, 0.94244236, 1.0328076, 0.9416909, 0.8554093, 0.85841954, 0.86125344, 0.8...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>unsaltedbutter shortening darkbrownsugar whitesugar hardboiledeggs extract cakeflour bakingsoda cinnamonsticks fineseasalt rolledoats goldenraisins</td>\n",
       "      <td>two</td>\n",
       "      <td>[1.1159946, 1.0218182, 1.0490594, 1.1337346, 1.0819193, 1.0001538, 0.88156396, 1.0363054, 1.051347, 0.95685035, 0.97760034, 1.1465247, 1.0635517, 1.0436127, 1.0543605, 0.91675234, 1.0316187, 0.91868937, 1.026214, 1.0461168, 0.93609893, 0.9501556, 0.9354748, 1.0920302, 0.9907964, 1.0375928, 1.1761835, 0.9737048, 1.0834461, 0.8357477, 0.9849128, 0.8694957, 1.0597687, 1.0888761, 1.06421, 0.95366836, 0.8026761, 0.7020069, 0.8705663, 1.0084169, 0.84224504, 0.9776508, 1.014047, 0.905882, 0.9256118...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ice fineseasalt saltedbutter cakeflour crackedblackpepper sourcream</td>\n",
       "      <td>two</td>\n",
       "      <td>[1.0208696, 0.8956686, 0.9728144, 1.0291171, 1.0226023, 0.94862574, 0.99734336, 0.93378246, 1.0737027, 1.0024935, 1.0243517, 1.140763, 1.0883409, 0.9505637, 1.1412833, 0.91788536, 1.0551171, 0.9271432, 0.98769516, 1.0484502, 1.0087765, 1.0287459, 0.9814383, 1.0381069, 1.1644434, 0.9881387, 0.9279215, 0.96617115, 0.9829312, 0.9840515, 1.0381478, 0.9458911, 1.1932281, 1.0924323, 0.99459827, 1.0041562, 0.95646423, 1.0044742, 1.0243413, 0.9750632, 1.0100434, 0.8849414, 0.9189506, 0.9548748, 0.85...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>saltedbutter sweetpotatoes pineapple puremaplesyrup cinnamonsticks fineseasalt choppedwalnuts</td>\n",
       "      <td>three</td>\n",
       "      <td>[0.94134396, 0.9448274, 1.1270329, 1.0474855, 1.0135624, 0.9859547, 1.0360261, 1.0584407, 0.9569531, 0.9783981, 1.0456549, 0.96260124, 1.0520508, 0.9978982, 0.9971763, 1.0118853, 0.96883535, 1.0734411, 0.8983274, 0.89759463, 1.1181602, 0.952811, 1.0497954, 0.8719612, 0.97365314, 0.95314246, 0.94482756, 1.1465884, 0.97682005, 0.93854696, 0.94228876, 1.1158723, 0.9636974, 0.97239214, 0.91030145, 0.9083359, 0.8979536, 0.9750195, 0.9319171, 1.1035287, 1.0131791, 0.92877036, 0.9360023, 0.98186535...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>hamburgerbuns pastasauce</td>\n",
       "      <td>two</td>\n",
       "      <td>[0.95170057, 0.97133154, 1.032432, 0.99357784, 1.0231296, 1.0267057, 0.96467626, 0.97659945, 1.031161, 0.9527002, 0.9483558, 0.955703, 1.016209, 1.0348122, 0.97074485, 1.0066906, 1.0790608, 0.96130866, 1.0805751, 1.0460703, 1.0799003, 1.0432367, 0.9945421, 0.96325433, 1.0174834, 1.0233452, 1.0110447, 1.0008507, 1.0395622, 1.0097884, 1.003967, 1.0040532, 0.9667837, 0.9902145, 0.9708406, 1.0060093, 1.0085346, 0.93761873, 1.0009837, 0.94310814, 0.9460053, 1.0362029, 1.0604507, 0.9732361, 0.9408...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                RECIPE  \\\n",
       "0                            toastedsesameoil oliveoil nutbutter cidervinegar honey groundcayennepepper limewedges freshspinach spearmint springonions   \n",
       "1                               oliveoil cakeflour whiteonion choppedgarlic whitewine grapetomatoes chickenbouillon tomatopaste darkbrownsugar parsley   \n",
       "2             fineseasalt crackedblackpepper choppedgarlic whiteonion ice freshbasil freshoregano freshthymeleaves saltedbutter shreddedparmesancheese   \n",
       "3  unsaltedbutter shortening darkbrownsugar whitesugar hardboiledeggs extract cakeflour bakingsoda cinnamonsticks fineseasalt rolledoats goldenraisins   \n",
       "4                                                                                  ice fineseasalt saltedbutter cakeflour crackedblackpepper sourcream   \n",
       "5                                                        saltedbutter sweetpotatoes pineapple puremaplesyrup cinnamonsticks fineseasalt choppedwalnuts   \n",
       "6                                                                                                                             hamburgerbuns pastasauce   \n",
       "\n",
       "     WHO  \\\n",
       "0    two   \n",
       "1    two   \n",
       "2    one   \n",
       "3    two   \n",
       "4    two   \n",
       "5  three   \n",
       "6    two   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          embed_summed  \n",
       "0  [1.1235876, 1.1093943, 1.0867372, 0.85236037, 0.89380324, 0.8650725, 0.98391545, 0.9461132, 0.9469015, 1.0970093, 0.8552572, 1.0715595, 0.9841607, 1.013585, 0.97388107, 0.9736649, 1.0155487, 0.99108434, 0.9708908, 0.97684455, 1.1266869, 1.1471821, 0.95085275, 0.87351066, 1.1188335, 1.1121885, 1.1366059, 0.9685107, 1.029752, 0.9673499, 0.85247856, 1.1385634, 0.9708395, 1.1972069, 0.83814836, 1.0772746, 0.9607101, 1.0581956, 0.96407497, 1.0055512, 0.92251134, 0.89204025, 0.9902143, 1.0689365, ...  \n",
       "1  [1.1576535, 1.0060086, 1.001102, 1.0257555, 0.965866, 1.0820988, 1.2114697, 1.0102463, 1.1409972, 0.9423051, 0.9791293, 1.1181381, 0.95848656, 0.8784251, 1.0353574, 0.9220266, 1.115515, 1.0678421, 1.2171474, 0.95343775, 1.0700219, 0.96431077, 0.96083665, 1.0005562, 1.1521571, 0.927994, 1.1126252, 0.93517196, 1.0194654, 0.9289029, 0.864626, 0.94313383, 0.9287649, 1.0493382, 0.7741933, 0.85782766, 0.89068496, 1.061048, 0.9233977, 0.98739916, 0.89586186, 0.9407691, 0.9297667, 1.0341085, 0.97049...  \n",
       "2  [0.80973685, 0.86391956, 1.0316488, 1.0032533, 0.95308906, 0.93657243, 1.040899, 0.9817769, 1.0761225, 1.0651423, 1.0227959, 1.0026183, 1.1349108, 0.97062963, 1.2304887, 0.8398581, 1.022866, 1.0837965, 1.090834, 1.161133, 0.9819236, 1.0737371, 1.0018833, 0.95574737, 0.98670936, 0.82360303, 0.9653919, 0.8880768, 0.95349425, 1.0639567, 0.9214981, 1.0225074, 1.2548019, 1.1158266, 0.93849015, 0.896206, 0.9210321, 1.1299094, 0.94244236, 1.0328076, 0.9416909, 0.8554093, 0.85841954, 0.86125344, 0.8...  \n",
       "3  [1.1159946, 1.0218182, 1.0490594, 1.1337346, 1.0819193, 1.0001538, 0.88156396, 1.0363054, 1.051347, 0.95685035, 0.97760034, 1.1465247, 1.0635517, 1.0436127, 1.0543605, 0.91675234, 1.0316187, 0.91868937, 1.026214, 1.0461168, 0.93609893, 0.9501556, 0.9354748, 1.0920302, 0.9907964, 1.0375928, 1.1761835, 0.9737048, 1.0834461, 0.8357477, 0.9849128, 0.8694957, 1.0597687, 1.0888761, 1.06421, 0.95366836, 0.8026761, 0.7020069, 0.8705663, 1.0084169, 0.84224504, 0.9776508, 1.014047, 0.905882, 0.9256118...  \n",
       "4  [1.0208696, 0.8956686, 0.9728144, 1.0291171, 1.0226023, 0.94862574, 0.99734336, 0.93378246, 1.0737027, 1.0024935, 1.0243517, 1.140763, 1.0883409, 0.9505637, 1.1412833, 0.91788536, 1.0551171, 0.9271432, 0.98769516, 1.0484502, 1.0087765, 1.0287459, 0.9814383, 1.0381069, 1.1644434, 0.9881387, 0.9279215, 0.96617115, 0.9829312, 0.9840515, 1.0381478, 0.9458911, 1.1932281, 1.0924323, 0.99459827, 1.0041562, 0.95646423, 1.0044742, 1.0243413, 0.9750632, 1.0100434, 0.8849414, 0.9189506, 0.9548748, 0.85...  \n",
       "5  [0.94134396, 0.9448274, 1.1270329, 1.0474855, 1.0135624, 0.9859547, 1.0360261, 1.0584407, 0.9569531, 0.9783981, 1.0456549, 0.96260124, 1.0520508, 0.9978982, 0.9971763, 1.0118853, 0.96883535, 1.0734411, 0.8983274, 0.89759463, 1.1181602, 0.952811, 1.0497954, 0.8719612, 0.97365314, 0.95314246, 0.94482756, 1.1465884, 0.97682005, 0.93854696, 0.94228876, 1.1158723, 0.9636974, 0.97239214, 0.91030145, 0.9083359, 0.8979536, 0.9750195, 0.9319171, 1.1035287, 1.0131791, 0.92877036, 0.9360023, 0.98186535...  \n",
       "6  [0.95170057, 0.97133154, 1.032432, 0.99357784, 1.0231296, 1.0267057, 0.96467626, 0.97659945, 1.031161, 0.9527002, 0.9483558, 0.955703, 1.016209, 1.0348122, 0.97074485, 1.0066906, 1.0790608, 0.96130866, 1.0805751, 1.0460703, 1.0799003, 1.0432367, 0.9945421, 0.96325433, 1.0174834, 1.0233452, 1.0110447, 1.0008507, 1.0395622, 1.0097884, 1.003967, 1.0040532, 0.9667837, 0.9902145, 0.9708406, 1.0060093, 1.0085346, 0.93761873, 1.0009837, 0.94310814, 0.9460053, 1.0362029, 1.0604507, 0.9732361, 0.9408...  "
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3.head(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jermainemarshall/anaconda3/lib/python3.6/site-packages/pandas/core/generic.py:4401: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self[name] = value\n"
     ]
    }
   ],
   "source": [
    "df3.embed_summed= df3['embed_summed'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jermainemarshall/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "/Users/jermainemarshall/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/Users/jermainemarshall/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  after removing the cwd from sys.path.\n",
      "/Users/jermainemarshall/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "df3.embed_summed.str.replace('[','')\n",
    "df3['embed_summed'] = df3['embed_summed'].str.replace('[', '')\n",
    "df3['embed_summed'] = df3['embed_summed'].str.replace(']', '')\n",
    "df3['embed_summed'] = df3['embed_summed'].str.replace('[\\n\\s]+', ',')\n",
    "df3['embed_summed'] = df3['embed_summed'].str.replace(r'^,', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4 = df3['embed_summed'].apply(lambda x: pd.Series(x.split(',')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3= df3[['RECIPE','WHO']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3= df3.join(df4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RECIPE</th>\n",
       "      <th>WHO</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>...</th>\n",
       "      <th>90</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>toastedsesameoil oliveoil nutbutter cidervinegar honey groundcayennepepper limewedges freshspinach spearmint springonions</td>\n",
       "      <td>two</td>\n",
       "      <td>1.1235876083374023437500000000000000000000000000</td>\n",
       "      <td>1.1093943119049072265625000000000000000000000000</td>\n",
       "      <td>1.0867371559143066406250000000000000000000000000</td>\n",
       "      <td>0.8523603677749633789062500000000000000000000000</td>\n",
       "      <td>0.8938032388687133789062500000000000000000000000</td>\n",
       "      <td>0.8650724887847900390625000000000000000000000000</td>\n",
       "      <td>0.9839154481887817382812500000000000000000000000</td>\n",
       "      <td>0.9461132287979125976562500000000000000000000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0437570810317993164062500000000000000000000000</td>\n",
       "      <td>0.9487783312797546386718750000000000000000000000</td>\n",
       "      <td>0.9575373530387878417968750000000000000000000000</td>\n",
       "      <td>0.8360086083412170410156250000000000000000000000</td>\n",
       "      <td>0.9395383000373840332031250000000000000000000000</td>\n",
       "      <td>0.9876493811607360839843750000000000000000000000</td>\n",
       "      <td>0.7833659648895263671875000000000000000000000000</td>\n",
       "      <td>1.0034283399581909179687500000000000000000000000</td>\n",
       "      <td>1.1035661697387695312500000000000000000000000000</td>\n",
       "      <td>1.0117907524108886718750000000000000000000000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 102 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                      RECIPE  \\\n",
       "0  toastedsesameoil oliveoil nutbutter cidervinegar honey groundcayennepepper limewedges freshspinach spearmint springonions   \n",
       "\n",
       "   WHO                                                 0  \\\n",
       "0  two  1.1235876083374023437500000000000000000000000000   \n",
       "\n",
       "                                                  1  \\\n",
       "0  1.1093943119049072265625000000000000000000000000   \n",
       "\n",
       "                                                  2  \\\n",
       "0  1.0867371559143066406250000000000000000000000000   \n",
       "\n",
       "                                                  3  \\\n",
       "0  0.8523603677749633789062500000000000000000000000   \n",
       "\n",
       "                                                  4  \\\n",
       "0  0.8938032388687133789062500000000000000000000000   \n",
       "\n",
       "                                                  5  \\\n",
       "0  0.8650724887847900390625000000000000000000000000   \n",
       "\n",
       "                                                  6  \\\n",
       "0  0.9839154481887817382812500000000000000000000000   \n",
       "\n",
       "                                                  7  \\\n",
       "0  0.9461132287979125976562500000000000000000000000   \n",
       "\n",
       "                         ...                         \\\n",
       "0                        ...                          \n",
       "\n",
       "                                                 90  \\\n",
       "0  1.0437570810317993164062500000000000000000000000   \n",
       "\n",
       "                                                 91  \\\n",
       "0  0.9487783312797546386718750000000000000000000000   \n",
       "\n",
       "                                                 92  \\\n",
       "0  0.9575373530387878417968750000000000000000000000   \n",
       "\n",
       "                                                 93  \\\n",
       "0  0.8360086083412170410156250000000000000000000000   \n",
       "\n",
       "                                                 94  \\\n",
       "0  0.9395383000373840332031250000000000000000000000   \n",
       "\n",
       "                                                 95  \\\n",
       "0  0.9876493811607360839843750000000000000000000000   \n",
       "\n",
       "                                                 96  \\\n",
       "0  0.7833659648895263671875000000000000000000000000   \n",
       "\n",
       "                                                 97  \\\n",
       "0  1.0034283399581909179687500000000000000000000000   \n",
       "\n",
       "                                                 98  \\\n",
       "0  1.1035661697387695312500000000000000000000000000   \n",
       "\n",
       "                                                 99  \n",
       "0  1.0117907524108886718750000000000000000000000000  \n",
       "\n",
       "[1 rows x 102 columns]"
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3.to_csv('Embeddings_files_no_amounts/subtract_yummly_embeddings_no_counts.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for w in df2['RECIPE'][0].split():\n",
    "    \n",
    "    print(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_embed_p(wordstr):\n",
    "    sum = 0\n",
    "    \n",
    "    if word in embedding_dict:\n",
    "        for i,word in embedding_dict.items():\n",
    "            sum+=i[word]\n",
    "    return sum\n",
    "            \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_embeddings['soup'].flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_model=Model(inputs=[desc_input,target_title_input,neg_title_input],outputs=[pos_title_logit,neg_title_logit])\n",
    "\n",
    "\n",
    "original_model.compile(optimizer='adam',metrics=['accuracy'],\n",
    "                       loss=['binary_crossentropy','binary_crossentropy'],loss_weights=[1.,1.])                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_model.fit_generator(trainGen,verbose=1,validation_data=validateGen,epochs=5, steps_per_epoch= 30,\n",
    "                             workers=n_workers,max_queue_size=queue_size,use_multiprocessing=False,shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "open('all_recipe_model.json'.format(model_name), 'w').write(original_model.to_json())\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "original_model.save_weights('all_recipe_model.hdf5'.format(name=model_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
